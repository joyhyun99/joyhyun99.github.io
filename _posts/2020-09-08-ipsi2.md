---
layout: post
title: "[KOR] 지원자 점수대를 유형별로 나누어 최종등록여부를 분류하는 모델 구축"
feature-img: assets/img/pexels/triangular.jpeg
thumbnail: "assets/img/f8.jpeg"
tags: [ipsi, project, deep-learning, data-science]
author: joey99
excerpt_separator: <!--more-->
---

<p>  Establishment of KorSAT final registration model that determines cut-off score based on previous results and preferences </p>
<!--more-->

## 서론
* TOC
{:toc}

<p> 저번 입시통계 칼럼에서는 점수대에 따른 선호도 순위에 따라 최종 등록 여부를 분류하는 모델을 구축해보았다면, </p>

<p> 오늘은 지원자의 점수대에 따라 군집 분석 기법 (클러스터링 기법)을 이용해 이전 지원자 점수, 합격 여부, 그리고 최종 등록 여부를 토대로 지원자를 유형별로 나누는 비지도 학습 알고리즘을 이용하여 최종등록모델을 구축하였습니다. </p>

## 군집파악, 합격으로 향한 지름길

![0]({{ "/assets/img/f5.jpg" | relative_url }})

<p> 우리 주위에서 발생하는 사건들은, 동전을 던지는 행위와 같이 특정 범위 내에서 동일한 확률로 발생할 확률을 가진 균일 분포 (Uniform Distribution)을 따르기 보다는, 수능 성적을 모두가 동일한 확률로 랜덤하게 점수를 받는 것 같지 않듯이 사건이 발생할 확률이 서로 다른 분포를 가진 비정규분포를 주로 따라간다.  </p>

<p> 미국 메이저리그 선수들의 달리기 속도를 조사해서 정리한 위의 히스토그램을 예로 들어보자. 어느 느린 선수는 1초에 24피트밖에 뛰지 못하고 어느 빠른 선수는 1초에 30피트의 속도로 질주하지만, 60% 이상의 선수들은 1초에 26피트에서 28피트 사이의 속도에서 질주한다. 이처럼 대부분 사건의 분포는 균등하지 않고, 어느 한 부분에서 군집하는 경향성을 가진다. </p>

![1]({{ "/assets/img/f6.png" | relative_url }})

<p> 사실 거의 모든 사건이 어느 한 부분에 군집하여 있는 비정규분포, 혹은 정규분포도 우리 생각 만큼은 흔하지는 않다. 고등과정을 공부하거나 통계문제를 풀 때에는 대부분 정규분포로 가정해 모수를 가정하는 모수적 방법을 사용하지만, 찍먹 vs 부먹의 케이스와 같이 보통의 사례에서는 어느 양 극단에서 표본이 군집하는 경향성이 생기거나, 두개의 극단 그 이상의 군집이 형성되는 케이스도 있을 것이다. 위의 그래프와 같이 표본이 두개의 부분에 군집하는 경향성이 보인다면, 이 데이터를 분석하기 위해 군집 분포를 사용할 수 있다. </p>

![2]({{ "/assets/img/f7.jpeg" | relative_url }})

<p> 군집 분포, 쉽게 말해서 클러스터링 기법은 간단하게 서로 비슷한 경향성을 가진 분포들을 묶고, 다른 군집에 있는 분포들과 차별화를 두어 나누는 기법이다. 위 그래프의 왼쪽에 있는 분포를 군집 1이라고 하고, 오른쪽에 있는 분포를 군집 2라고 하면, 각가의 평균, 표준편차 등 간단한 기준으로 두 군집을 나누어 통계적으로 서로 비교할 수 있는 기반을 만들어 낼 수 있다. </p>

![3]({{ "/assets/img/f4.png" | relative_url }})

<p> 서론이 길었지만, 핵심은 바로 우리가 관심있어하는 입시 지원에서도 지원자 점수대를 분석해 군집화한 후 분석해 우리가 원하는 대로 유용하게 사용할 수 있다는 것이다. 보통 최초합격과 추가합격의 커트라인은 입시 모의지원 사이트가 제시한 커트라인대에 분포하여 있는 경향성이 있는데, 이 지원자 점수들을 군집화해 어느 점수대에서 지원자들이 몰려있는지 분석하고, 너무 높으면 폭발을 예상하고 빼고, 상대적으로 분포 정도가 낮은 점수대의 학과에 지원해 합격 가능성을 아주 큰 폭으로 늘리는 방도로 사용할 수 있다. </p>

<p> 여러가지 요소들을 차원 축소한 자료를 정리한 위의 그래프를 예시로 들자면, 위 분포는 많게는 최초합격과 추가합격을 구분하는 커트까지 합쳐서 5가지, 적게는 4가지 군집으로 분류하여 분석할 수 있다. 1번, 2번, 3번 군집에 있는 데이터는 불합격할 확률이 높고, 4번 군집에 있는 데이터는 최소한의 합격이 보장되어 있는 데이터이다. 다만 2번과 3번 군집에도 추가합격한 데이터가 존재하는데, 이 데이터들은 나중에 업로드할 다른 분석기법을 통해 알아내 남들이 모르는 빵구를 예상해 큰 이득을 얻을 수 있다. </p>

## 알고리즘 분석 과정

<p> 이번에도 OO 대학교 XX 학과에 2019년도에 180명의 지원자가 정시모집에 지원했다고 가정합시다. 최종지원 모델은 지원자 점수대, 최종 결과, 등록 여부 데이터를 사용했다. </p>

<p> 점수대에 따른 지원 여부를 분석할 때에는 산업 현장은 물론 학계에서도 널리 사용되는 K-평균++ 기법을 사용해 초기 클러스터 센트로이드를 똑똑하게 할당하였고, 여러가지 요소들을 초평면으로 압축해 분석한 그래프에서는 비지도 선형 변환 기법인 PCA를 사용해 분류를 진행하였다. </p>

![4]({{ "/assets/img/f1.png" | relative_url }})

<p> K-평균 ++ 기법을 사용해 군집을 분류해 실제 데이터와 비교한 그래프이다. 아직 표본이 많이 쌓이지 않았고, 이 기법으로 데이터들을 분석하는 것이 익숙치 않아 예측과 실제가 다른 정도를 나타낸 추세선의 기울기가 일정하지 않은 것을 확인할 수 있다. 이 문제를 해결하기 위해서는 이 쪽으로 학습을 더 하여 더 나은 성능을 보이는 분류기를 사용하거나, 이 오차를 나타내는 추세선을 분류하여 분석해 여러 다른 군집을 분류해 낼 수 있다. </p>

![5]({{ "/assets/img/f2.png" | relative_url }})

<p> PCA를 사용한 차원 축소를 완료한 데이터를 나타낸 그래프이다. 위에서 이미 설명했기에 중요하게 설명할 점은 없고, 기계가 스스로 학습해 불합격, 최초합격, 추가합격을 나누는 분류학습을 하게 하도록 작업하고 있다. 이 프로그램이 실용화될 때에는 그래프에서 최초합격, 추가합격, 불합격이 나누어 표시된 그래프를 볼 수 있을 것이다. </p>

## 최종 레포트





