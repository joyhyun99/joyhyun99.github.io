---
layout: post
title: "[KOR] 지원자의 점수대와 선호도를 바탕으로 최종등록여부를 판별하는 모델 구축"
feature-img: assets/img/pexels/triangular.jpeg
thumbnail: "assets/img/ca1.jpeg"
tags: [ipsi, project, deep-learning, data-science]
author: joey99
excerpt_separator: <!--more-->
---

<p>  Establishment of KorSAT Preference model that determines final registration based on applicants' scores and preferences </p>
<!--more-->

## 서론
* TOC
{:toc}

<p>  9월 모의고사가 얼마 안 남은 이 시점, 어려운 환경 속에서도 잘 헤쳐나가고 계신가요? 아무리 힘들어도 걱정하지 마세요. 그 시점이 오늘이 되었든 내일이 되었든 분명히 고생한 만큼 그 이상으로 돌려받을 거에요. 조금만 더 힘을 냅시다! </p>

<p>  오늘의 고생이 드디어 수능날에 복에 되어 돌아와 성적을 생각 그 이상으로 받았으면, 이제 원하는 대학, 원하는 학과에 성공적으로 붙을 수 있을 입시 전략을 짜야할 시기입니다. 하지만 이전까지는 평범한 학생 입장에서는 쓸 수 있는 도구가 한정되어 있었습니다. 비유하자면 수능 샤프 달랑 하나만 가지고 전쟁터에 나간 느낌이지요.  </p>

<p>  할 수 있는 방도라면은 입시 모의지원 사이트에 들어가서 성적레포트를 확인해서 칸수대로 지원 전략을 세우거나, 더 세부적으로 들어가자면 성적 데이터를 가지고 일일히 1순위 2순위 엑셀 노가다해서 얻은 감을 믿고 지원하는게 보통입니다. 이렇게 하면은 그냥 아무런 생각 없이 지원하는 것보다는 합격 확률을 높일 수는 있지만, 갑자기 마지막날에 표본이 몰려 틀린 결과가 나올수도 있고 자신의 감을 바탕으로 결정을 내렸기 때문에 통계적으로도 올바른 방식이 아닙니다 </p>

<p>  이 때문에, print('Hello World')도 할 줄 모르는 평범한 고3, 재수생 학생이더라도 코드 한줄만 적으면 데이터 사이언스에 인공지능 학습 알고리즘들을 가미한  매우 강력한 데이터 분석 레포트를 제작해서 수능 이후에 입시에 관련해서 여러가지 수학적인 지표를 공유할 예정이니다. </p>

>- 이름하여 SB 지표!

<p>  이번 첫번째 칼럼에서는 선호도를 이용해 등록 여부를 판별할 수 있는 모델을 설명해드리겠습니다. 혹여나 이해가 되지 않으시더라도 하나도 상관 없습니다 그냥 이렇게 프로그램을 작업중이라고 파악하시면 됩니다 :D </p>

## 선호도의 중요성

<p>  각 지원자의 선호도는 그 순서만으로는 합격 여부를 결정할 수는 없지만, 최초합격에다가 3순위면 최종적으로 그 학과에 등록하지 않을 가능성이 높고, 추가합격에다가 1순위면 최종적으로 그 학과에 등록할 확률이 아주 높아서 내 점수보다 위에 있는 표본의 점수대가 선호도가 얼마면 몇퍼센트의 확률로 등록할지 말지의 여부를 통계적으로 활용할 수 있는 중요한 지표 중 하나입니다. 학생들의 선호도를 점수대에 따라 확인하기 위해 점수대에 따른 선호도 분포 그래프를 먼저 첨부하였습니다. 이를 통해 모델을 구축하기 전 전체적인 선호도를 파악할 수 있습니다.</p>

![0]({{ "/assets/img/ca2.png" | relative_url }})


## 알고리즘 분석 과정

<p>  OO 대학교 XX 학과에 2019년도에 180명의 지원자가 정시모집에 지원했다고 가정합시다. 선호도 모델은 선호도, 지원자 점수대, 등록 여부 데이터로 구축하였습니다. </p>
<p>  모델에 들어갈 최적의 학습 알고리즘 파악하기 위해, Keras, Tensorflow 등등 다양한 강력한 도구들이 있지만, 저는 사이킷런을 이용한 학습을 통해 로지스틱 회귀, 결정 트리 학습법, K- 최근접 이웃 알고리즘, 다수결 투표 앙상블 분류기 각각 모델의 위양성과 진음성을 구하고, 이를 바탕으로 정밀도, 재현율을 측정해 가장 성능이 좋은 학습 알고리즘을 사용하였습니다.</p>

{% highlight ruby %}
{% raw %}
ROC AUC: 0.82 (+/- 0.10) [Logistic regression]
ROC AUC: 0.84 (+/- 0.07) [Decision tree]
ROC AUC: 0.65 (+/- 0.12) [KNN]
ROC AUC: 0.79 (+/- 0.08) [Majority voting]
{% endraw %}
{% endhighlight %}

{% highlight ruby %}
{% raw %}
최적의 매개변수: {'decisiontreeclassifier__max_depth': 1, 'pipeline-1__clf__C': 0.1}
정확도: 0.79
{% endraw %}
{% endhighlight %}

![1]({{ "/assets/img/ca3.png" | relative_url }})

## 알고리즘 분석 결과

<p> 알고리즘을 학습하고 난 뒤, 지원년도, 점수대와, 선호도를 넣은 코드 한 줄을 작성하면 데이터 분석 레포트와 더불어 학습 알고리즘이 계산한 결과 + 정밀도를 출력합니다.  </p>

{% highlight ruby %}
{% raw %}
750점대이고, 선호도가 1순위인 표본은 최종등록하는 데이터입니다.
정밀도 = 83.33 퍼센트 (총 180 가지 샘플)
{% endraw %}
{% endhighlight %}

{% highlight ruby %}
{% raw %}
잘못 분류된 샘플 개수: 10
정밀도 = 83.33 퍼센트 (총 180 가지 샘플)
(에이다부스트의 훈련 정확도 = 0.82, 에이다부스트의 테스트 정확도 = 0.83)
Cross Validation 정확도: 0.77 +/- 0.09
훈련 MSE: 0.175, 테스트 MSE: 0.167
훈련 R^2: 0.271, 테스트 R^2: 0.330
{% endraw %}
{% endhighlight %}

<p> 밑의 그래프는 학습 알고리즘이 데이터를 분류한 결과를 나타낸 그래프입니다. 여러 학과의 선호도를 분석한 다음, 이 그래프들을 가지고 클러스터링 기법을 통해 유형화하여 종류에 따라 분류할 수 있습니다. </p>

![2]({{ "/assets/img/ca5.png" | relative_url }})

## 최종 레포트

<p> 앞의 예시에서 코드 단 한줄로 매우 강력한 데이터분석 레포트를 만드는 과정을 설명드렸습니다. 주어진 데이터에 따라 맞는 결과를 산출하고, 그 때마다 달리할 점은 코드 몇 단어면 충분하기 때문에 매우 빠르고 쉽게 자신이 원하는 데이터를 얻을 수 있습니다. </p>

```python
preference_SB(_2019, 740, 1)
```


![png](/assets/img/output_0_0.png)


    선호도 1순위: 점수대 = [670, 680, 690, 700, 710, 720, 730, 740, 750, 760, 770] 지원자 수 = [ 6  7  8  4  9  5  5 15  3  5  5]
    선호도 2순위: 점수대 = [670, 680, 690, 700, 710, 720, 730, 740, 750, 760, 770] 지원자 수 = [3 2 3 3 6 5 6 4 5 4 7]
    선호도 3순위: 점수대 = [670, 680, 690, 700, 710, 720, 730, 740, 750, 760, 770, 780] 지원자 수 = [2 5 4 5 5 6 3 6 9 8 6 1]
    


![png](/assets/img/output_0_2.png)


    선호도 1순위: 등록하지 않은 지원자 수 = 32, 최종등록한 지원자 수 = 25
    선호도 2순위: 등록하지 않은 지원자 수 = 20, 최종등록한 지원자 수 = 21
    선호도 3순위: 등록하지 않은 지원자 수 = 35, 최종등록한 지원자 수 = 17
    등록하지 않은 지원자 수 = 87, 최종등록한 지원자 수 = 63
    
    
    ROC AUC: 0.82 (+/- 0.10) [Logistic regression]
    ROC AUC: 0.84 (+/- 0.07) [Decision tree]
    ROC AUC: 0.65 (+/- 0.12) [KNN]
    ROC AUC: 0.79 (+/- 0.08) [Majority voting]
    


![png](/assets/img/output_0_4.png)


    
    최적의 매개변수: {'decisiontreeclassifier__max_depth': 1, 'pipeline-1__clf__C': 0.1}
    정확도: 0.79
    
    ------------------------------------------
    
    
    750점대이고, 선호도가 1순위인 표본은 최종등록하는 데이터입니다.
    정밀도 = 83.33 퍼센트 (총 180 가지 샘플)
    
    
    ------------------------------------------
    
    잘못 분류된 샘플 개수: 10
    정밀도 = 83.33 퍼센트 (총 180 가지 샘플)
    (에이다부스트의 훈련 정확도 = 0.82, 에이다부스트의 테스트 정확도 = 0.83)
    Cross Validation 정확도: 0.77 +/- 0.09
    훈련 MSE: 0.175, 테스트 MSE: 0.167
    훈련 R^2: 0.271, 테스트 R^2: 0.330
    
    


![png](/assets/img/output_0_6.png)



```python

```

## 데이터의 사용처

>- 전체적인 모델 구축: 선호도 모델만으로는 개개인 학생의 합불 여부를 판단할 수는 없지만, 이 모델을 다중신경망의 하나의 뉴런으로 설정하고, 다른 모델하고 합쳐 큰 인공신경망을 구축한다면, 더 나은 결과를 산출할 수 있습니다.

>- 입학처에서 사용: 입학처에서는 점수가 높은 학생들을 더 많이 포집하고 싶어하는 데, 이 모델을 통해 높은 점수대의 학생들이 어느 학과를 선호하는지 분석해 그 고득점자들을 위한 전략을 수립할 수 있습니다.

>- 학과별로 비교: 다른 대학, 동일한 학과의 레포트들을 산출해 그 학과가 학생들에게 어느 정도 선호도가 있는지 파악할 수 있습니다.

>- 대학 안에서 비교: 동일한 대학 내의 레포트들을 산출해 어느 학과의 학생선호도가 높은지 파악할 수 있습니다.

>- 학생: 자기 표본 위의 점수대의 학생의 선호도에 따라 어느 정도 확률로 빠져나가는 표본인지 분석해 알맞는 입시 전략을 구축할 수 있습니다.
