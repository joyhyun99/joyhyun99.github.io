```python
preference_SB(_2019, 740, 1)
```


![png](output_0_0.png)


    선호도 1순위: 점수대 = [670, 680, 690, 700, 710, 720, 730, 740, 750, 760, 770] 지원자 수 = [ 6  7  8  4  9  5  5 15  3  5  5]
    선호도 2순위: 점수대 = [670, 680, 690, 700, 710, 720, 730, 740, 750, 760, 770] 지원자 수 = [3 2 3 3 6 5 6 4 5 4 7]
    선호도 3순위: 점수대 = [670, 680, 690, 700, 710, 720, 730, 740, 750, 760, 770, 780] 지원자 수 = [2 5 4 5 5 6 3 6 9 8 6 1]
    


![png](output_0_2.png)


    선호도 1순위: 등록하지 않은 지원자 수 = 32, 최종등록한 지원자 수 = 25
    선호도 2순위: 등록하지 않은 지원자 수 = 20, 최종등록한 지원자 수 = 21
    선호도 3순위: 등록하지 않은 지원자 수 = 35, 최종등록한 지원자 수 = 17
    등록하지 않은 지원자 수 = 87, 최종등록한 지원자 수 = 63
    
    
    ROC AUC: 0.82 (+/- 0.10) [Logistic regression]
    ROC AUC: 0.84 (+/- 0.07) [Decision tree]
    ROC AUC: 0.65 (+/- 0.12) [KNN]
    ROC AUC: 0.79 (+/- 0.08) [Majority voting]
    


![png](output_0_4.png)


    
    최적의 매개변수: {'decisiontreeclassifier__max_depth': 1, 'pipeline-1__clf__C': 0.1}
    정확도: 0.79
    
    ------------------------------------------
    
    
    750점대이고, 선호도가 1순위인 표본은 최종등록하는 데이터입니다.
    정밀도 = 83.33 퍼센트 (총 180 가지 샘플)
    
    
    ------------------------------------------
    
    잘못 분류된 샘플 개수: 10
    정밀도 = 83.33 퍼센트 (총 180 가지 샘플)
    (에이다부스트의 훈련 정확도 = 0.82, 에이다부스트의 테스트 정확도 = 0.83)
    Cross Validation 정확도: 0.77 +/- 0.09
    훈련 MSE: 0.175, 테스트 MSE: 0.167
    훈련 R^2: 0.271, 테스트 R^2: 0.330
    
    


![png](output_0_6.png)



```python

```
